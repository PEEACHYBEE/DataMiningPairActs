{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8a818d",
   "metadata": {},
   "source": [
    "# 9428 Aromin - Encarnacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b5843e",
   "metadata": {},
   "source": [
    "## 1. Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48acf62e",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a921b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   gender  age  educationLevel  currentSmoker  cigsPerDay  BPMeds  \\\n",
      "0       1   39             4.0              0         0.0     0.0   \n",
      "1       0   46             2.0              0         0.0     0.0   \n",
      "2       1   48             1.0              1        20.0     0.0   \n",
      "3       0   61             3.0              1        30.0     0.0   \n",
      "4       0   46             3.0              1        23.0     0.0   \n",
      "\n",
      "   prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  \\\n",
      "0                0             0         0    195.0  106.0   70.0  26.97   \n",
      "1                0             0         0    250.0  121.0   81.0  28.73   \n",
      "2                0             0         0    245.0  127.5   80.0  25.34   \n",
      "3                0             1         0    225.0  150.0   95.0  28.58   \n",
      "4                0             0         0    285.0  130.0   84.0  23.10   \n",
      "\n",
      "   heartRate  glucose  tenYearCHD  \n",
      "0       80.0     77.0           0  \n",
      "1       95.0     76.0           0  \n",
      "2       75.0     70.0           0  \n",
      "3       65.0    103.0           1  \n",
      "4       85.0     85.0           0  \n",
      "\n",
      "Dataset shape (rows, columns): (4238, 16)\n",
      "\n",
      "Missing values per column:\n",
      "gender               0\n",
      "age                  0\n",
      "educationLevel     105\n",
      "currentSmoker        0\n",
      "cigsPerDay          29\n",
      "BPMeds              53\n",
      "prevalentStroke      0\n",
      "prevalentHyp         0\n",
      "diabetes             0\n",
      "totChol             50\n",
      "sysBP                0\n",
      "diaBP                0\n",
      "BMI                 19\n",
      "heartRate            1\n",
      "glucose            388\n",
      "tenYearCHD           0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "tenYearCHD\n",
      "0    3594\n",
      "1     644\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load the dataset\n",
    "df = pd.read_csv('heart_disease_prediction.csv')\n",
    "\n",
    "#Display the first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "#Check the shape of the dataset\n",
    "print(\"\\nDataset shape (rows, columns):\", df.shape)\n",
    "\n",
    "#Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#Check for duplicates\n",
    "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n",
    "print(df.iloc[:, -1].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a847e65d",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e84d65baaa19b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T11:24:43.459475Z",
     "start_time": "2025-06-21T11:24:43.395461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalized columns: ['age', 'educationLevel', 'cigsPerDay', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']\n",
      "Binary columns (not normalized): ['gender', 'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes']\n",
      "\n",
      "Preprocessing complete. Data saved to 'processed_heart_data.csv'\n",
      "\n",
      "Final dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4238 entries, 0 to 4237\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   gender           4238 non-null   int64  \n",
      " 1   age              4238 non-null   float64\n",
      " 2   educationLevel   4238 non-null   float64\n",
      " 3   currentSmoker    4238 non-null   int64  \n",
      " 4   cigsPerDay       4238 non-null   float64\n",
      " 5   BPMeds           4238 non-null   float64\n",
      " 6   prevalentStroke  4238 non-null   int64  \n",
      " 7   prevalentHyp     4238 non-null   int64  \n",
      " 8   diabetes         4238 non-null   int64  \n",
      " 9   totChol          4238 non-null   float64\n",
      " 10  sysBP            4238 non-null   float64\n",
      " 11  diaBP            4238 non-null   float64\n",
      " 12  BMI              4238 non-null   float64\n",
      " 13  heartRate        4238 non-null   float64\n",
      " 14  glucose          4238 non-null   float64\n",
      " 15  tenYearCHD       4238 non-null   int64  \n",
      "dtypes: float64(10), int64(6)\n",
      "memory usage: 529.9 KB\n",
      "None\n",
      "\n",
      "First 5 rows:\n",
      "   gender       age  educationLevel  currentSmoker  cigsPerDay  BPMeds  \\\n",
      "0       1 -1.234951        2.008372              0   -0.756459     0.0   \n",
      "1       0 -0.418257        0.044486              0   -0.756459     0.0   \n",
      "2       1 -0.184916       -0.937456              1    0.941387     0.0   \n",
      "3       0  1.331800        1.026429              1    1.790309     0.0   \n",
      "4       0 -0.418257        1.026429              1    1.196063     0.0   \n",
      "\n",
      "   prevalentStroke  prevalentHyp  diabetes   totChol     sysBP     diaBP  \\\n",
      "0                0             0         0 -0.973973 -1.255196 -1.118089   \n",
      "1                0             0         0  0.326499 -0.528621 -0.152197   \n",
      "2                0             0         0  0.208274 -0.213772 -0.240006   \n",
      "3                0             1         0 -0.264625  0.876090  1.077119   \n",
      "4                0             0         0  1.154071 -0.092676  0.111228   \n",
      "\n",
      "        BMI  heartRate   glucose  tenYearCHD  \n",
      "0  0.331170   0.365635 -0.214084           0  \n",
      "1  0.795769   1.656291 -0.301390           0  \n",
      "2 -0.099112  -0.064584 -0.825227           0  \n",
      "3  0.756172  -0.925021  2.055879           1  \n",
      "4 -0.690419   0.795854  0.484366           0  \n"
     ]
    }
   ],
   "source": [
    "# STEP 1: DATA PREPROCESSING\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('heart_disease_prediction.csv')\n",
    "\n",
    "# 1. Drop constant columns\n",
    "constant_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "if constant_cols:\n",
    "    print(f\"Dropping constant columns: {constant_cols}\")\n",
    "    df = df.drop(columns=constant_cols)\n",
    "\n",
    "# 2. Handle missing values with imputation\n",
    "continuous_vars = ['cigsPerDay', 'totChol', 'BMI', 'heartRate', 'glucose']\n",
    "categorical_vars = ['BPMeds', 'educationLevel']\n",
    "\n",
    "# Impute continuous variables with median\n",
    "for col in continuous_vars:\n",
    "    if col in df.columns:  # Check if column exists after removing constants\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Impute categorical variables with mode\n",
    "for col in categorical_vars:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# 3. Handle outliers\n",
    "def handle_outliers(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return np.clip(series, lower_bound, upper_bound)\n",
    "\n",
    "outlier_cols = ['cigsPerDay', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']\n",
    "for col in outlier_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = handle_outliers(df[col])\n",
    "\n",
    "# 4. Identify binary columns (won't normalize these)\n",
    "binary_cols = [col for col in df.columns if\n",
    "               df[col].nunique() == 2 and\n",
    "               df[col].dtype in [np.int64, np.float64] and\n",
    "               col != 'tenYearCHD']\n",
    "\n",
    "# 5. Normalize non-binary continuous columns\n",
    "non_binary_continuous = [col for col in df.columns if\n",
    "                         col not in binary_cols and\n",
    "                         col != 'tenYearCHD' and\n",
    "                         df[col].dtype in [np.int64, np.float64]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[non_binary_continuous] = scaler.fit_transform(df[non_binary_continuous])\n",
    "\n",
    "print(\"\\nNormalized columns:\", non_binary_continuous)\n",
    "print(\"Binary columns (not normalized):\", binary_cols)\n",
    "\n",
    "# 6. Save processed data\n",
    "df.to_csv('processed_heart_data.csv', index=False)\n",
    "print(\"\\nPreprocessing complete. Data saved to 'processed_heart_data.csv'\")\n",
    "\n",
    "# Show final dataset info\n",
    "print(\"\\nFinal dataset information:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847be16",
   "metadata": {},
   "source": [
    "## 2. Dataset Splitting and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd561d3c0836c46a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T11:25:04.472537Z",
     "start_time": "2025-06-21T11:25:04.222128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['age', 'sysBP', 'prevalentHyp', 'diaBP', 'diabetes', 'gender', 'BPMeds', 'totChol', 'BMI', 'glucose', 'prevalentStroke', 'cigsPerDay', 'educationLevel']\n",
      "\n",
      "Model trained and artifacts saved\n",
      "\n",
      "Model Coefficients and Odds Ratios:\n",
      "            Feature  Coefficient  Odds_Ratio\n",
      "0               age     0.559102    1.749101\n",
      "11       cigsPerDay     0.318429    1.374966\n",
      "1             sysBP     0.296949    1.345747\n",
      "5            gender     0.196778    1.217474\n",
      "7           totChol     0.111710    1.118189\n",
      "10  prevalentStroke     0.094802    1.099441\n",
      "4          diabetes     0.094601    1.099220\n",
      "2      prevalentHyp     0.084798    1.088497\n",
      "6            BPMeds     0.058416    1.060156\n",
      "9           glucose     0.057447    1.059130\n",
      "8               BMI     0.009458    1.009502\n",
      "3             diaBP     0.004723    1.004735\n",
      "12   educationLevel    -0.006002    0.994016\n"
     ]
    }
   ],
   "source": [
    "# FEATURE SELECTION AND MODEL TRAINING\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Load processed data\n",
    "df = pd.read_csv('processed_heart_data.csv')\n",
    "\n",
    "# Feature selection using ANOVA F-test (alternative to p-values)\n",
    "X = df.drop('tenYearCHD', axis=1)\n",
    "y = df['tenYearCHD']\n",
    "\n",
    "# Calculate F-scores and p-values\n",
    "f_scores, p_values = f_classif(X, y)\n",
    "\n",
    "# Create feature importance DataFrame\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'F_Score': f_scores,\n",
    "    'P_Value': p_values\n",
    "}).sort_values('P_Value')\n",
    "\n",
    "# Select features with p-value < 0.05\n",
    "significant_features = feature_importance[feature_importance['P_Value'] < 0.05]['Feature'].tolist()\n",
    "print(f\"Selected features: {significant_features}\")\n",
    "\n",
    "# Data splitting\n",
    "# Split into 90% development and 10% unseen\n",
    "dev_df, unseen_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=df['tenYearCHD']\n",
    ")\n",
    "\n",
    "# Split development data into train and test (80-20)\n",
    "X_dev = dev_df[significant_features]\n",
    "y_dev = dev_df['tenYearCHD']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_dev, y_dev, test_size=0.2, random_state=42, stratify=y_dev\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save artifacts\n",
    "joblib.dump(model, 'logistic_regression_model.pkl')\n",
    "joblib.dump(scaler, 'feature_scaler.pkl')\n",
    "unseen_df.to_csv('unseen_data.csv', index=False)\n",
    "print(\"\\nModel trained and artifacts saved\")\n",
    "\n",
    "# Display coefficients\n",
    "coeff_df = pd.DataFrame({\n",
    "    'Feature': significant_features,\n",
    "    'Coefficient': model.coef_[0],\n",
    "    'Odds_Ratio': np.exp(model.coef_[0])\n",
    "}).sort_values('Odds_Ratio', ascending=False)\n",
    "\n",
    "print(\"\\nModel Coefficients and Odds Ratios:\")\n",
    "print(coeff_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93dac8f",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e090d52e47a4e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T11:25:39.621749Z",
     "start_time": "2025-06-21T11:25:39.514287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      3248\n",
      "           1       0.66      0.08      0.14       566\n",
      "\n",
      "    accuracy                           0.86      3814\n",
      "   macro avg       0.76      0.54      0.53      3814\n",
      "weighted avg       0.83      0.86      0.81      3814\n",
      "\n",
      "Accuracy: 0.8571\n",
      "Precision: 0.6567\n",
      "Recall: 0.0777\n",
      "F1 Score: 0.1390\n",
      "\n",
      "PERFORMANCE INTERPRETATION:\n",
      "- Model detects 7.8% of actual CHD cases (Recall)\n",
      "- 65.7% of CHD predictions are correct (Precision)\n",
      "- Overall balanced performance: 13.9% (F1 Score)\n"
     ]
    }
   ],
   "source": [
    "# MODEL EVALUATION\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import (confusion_matrix, classification_report,\n",
    "                           accuracy_score, precision_score, recall_score, f1_score)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "SELECTED_FEATURES = ['age', 'sysBP', 'prevalentHyp', 'diaBP', 'diabetes', 'gender', 'BPMeds', 'totChol', 'BMI', 'glucose', 'prevalentStroke', 'cigsPerDay', 'educationLevel']\n",
    "\n",
    "# Load artifacts\n",
    "model = joblib.load('logistic_regression_model.pkl')\n",
    "scaler = joblib.load('feature_scaler.pkl')\n",
    "\n",
    "# Load and prepare test data\n",
    "test_df = pd.read_csv('processed_heart_data.csv')\n",
    "unseen_indices = pd.read_csv('unseen_data.csv').index\n",
    "X_test = test_df[~test_df.index.isin(unseen_indices)].copy()\n",
    "y_test = X_test['tenYearCHD']\n",
    "\n",
    "# Select features using predefined list\n",
    "X_test = X_test[SELECTED_FEATURES]\n",
    "\n",
    "# Scale features\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No CHD', 'CHD'],\n",
    "            yticklabels=['No CHD', 'CHD'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Test Data')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Key metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\nPERFORMANCE INTERPRETATION:\")\n",
    "print(f\"- Model detects {recall*100:.1f}% of actual CHD cases (Recall)\")\n",
    "print(f\"- {precision*100:.1f}% of CHD predictions are correct (Precision)\")\n",
    "print(f\"- Overall balanced performance: {f1*100:.1f}% (F1 Score)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a47a4a",
   "metadata": {},
   "source": [
    "## 4. Prediction on Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46109710bbf4f69c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T11:25:48.375435Z",
     "start_time": "2025-06-21T11:25:48.357168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen Data Predictions:\n",
      "Number of cases: 424\n",
      "Actual CHD cases: 64 (1 = Yes)\n",
      "Predicted CHD cases: 8 (1 = Yes)\n",
      "Accuracy: 84.4%\n",
      "\n",
      "Sample predictions (0 = No, 1 = Yes):\n",
      "        age     sysBP   glucose  tenYearCHD Actual_CHD_Label  Predicted_CHD  \\\n",
      "0 -0.534928 -0.698155 -1.087146           1              Yes              0   \n",
      "1 -1.001610 -0.431744 -0.126777           0               No              0   \n",
      "2 -0.068246  2.038609 -0.126777           0               No              0   \n",
      "3  0.165095 -0.480183 -0.126777           0               No              0   \n",
      "4 -0.068246 -1.158319  1.968573           0               No              0   \n",
      "5 -1.118280  0.488583 -0.214084           0               No              0   \n",
      "6 -1.351621 -0.698155 -0.126777           0               No              0   \n",
      "7  0.981788  0.004200 -0.825227           1              Yes              0   \n",
      "8 -0.651598 -0.770813  0.658979           0               No              0   \n",
      "9 -1.001610 -1.206757  0.658979           0               No              0   \n",
      "\n",
      "  Predicted_CHD_Label  CHD_Probability  \n",
      "0                  No         0.089482  \n",
      "1                  No         0.039286  \n",
      "2                  No         0.424567  \n",
      "3                  No         0.197172  \n",
      "4                  No         0.085050  \n",
      "5                  No         0.043928  \n",
      "6                  No         0.030154  \n",
      "7                  No         0.107918  \n",
      "8                  No         0.054927  \n",
      "9                  No         0.035493  \n",
      "\n",
      "Final predictions saved to 'final_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION ON UNSEEN DATA\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Define selected features\n",
    "SELECTED_FEATURES = ['age', 'sysBP', 'prevalentHyp', 'diaBP', 'diabetes', 'gender', 'BPMeds', 'totChol', 'BMI', 'glucose', 'prevalentStroke', 'cigsPerDay', 'educationLevel']\n",
    "\n",
    "# Load artifacts\n",
    "model = joblib.load('logistic_regression_model.pkl')\n",
    "scaler = joblib.load('feature_scaler.pkl')\n",
    "unseen_df = pd.read_csv('unseen_data.csv')\n",
    "\n",
    "# Prepare unseen data\n",
    "X_unseen = unseen_df[SELECTED_FEATURES]\n",
    "y_unseen = unseen_df['tenYearCHD']\n",
    "X_unseen_scaled = scaler.transform(X_unseen)\n",
    "\n",
    "# Make predictions\n",
    "y_unseen_pred = model.predict(X_unseen_scaled)\n",
    "y_unseen_prob = model.predict_proba(X_unseen_scaled)[:, 1]  # Probability of CHD\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = unseen_df.copy()\n",
    "results_df['Predicted_CHD'] = y_unseen_pred\n",
    "results_df['CHD_Probability'] = y_unseen_prob\n",
    "results_df['Prediction_Correct'] = results_df['tenYearCHD'] == results_df['Predicted_CHD']\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('final_predictions.csv', index=False)\n",
    "\n",
    "# Print results\n",
    "print(\"Unseen Data Predictions:\")\n",
    "print(f\"Number of cases: {len(unseen_df)}\")\n",
    "print(f\"Actual CHD cases: {y_unseen.sum()} (1 = Yes)\")\n",
    "print(f\"Predicted CHD cases: {y_unseen_pred.sum()} (1 = Yes)\")\n",
    "print(f\"Accuracy: {(results_df['Prediction_Correct'].mean()*100):.1f}%\")\n",
    "\n",
    "# Create display-friendly version for sample output\n",
    "display_df = results_df[['age', 'sysBP', 'glucose', 'tenYearCHD', 'Predicted_CHD', 'CHD_Probability']].copy()\n",
    "display_df['Actual_CHD_Label'] = results_df['tenYearCHD'].map({0: 'No', 1: 'Yes'})\n",
    "display_df['Predicted_CHD_Label'] = results_df['Predicted_CHD'].map({0: 'No', 1: 'Yes'})\n",
    "\n",
    "print(\"\\nSample predictions (0 = No, 1 = Yes):\")\n",
    "print(display_df[['age', 'sysBP', 'glucose', 'tenYearCHD', 'Actual_CHD_Label',\n",
    "                 'Predicted_CHD', 'Predicted_CHD_Label', 'CHD_Probability']].head(10))\n",
    "\n",
    "print(\"\\nFinal predictions saved to 'final_predictions.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env40",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
